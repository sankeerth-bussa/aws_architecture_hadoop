- name: configuring hadoop cluster
  hosts: all
  vars:
          path1: "/root/"
          path2: "/etc/hadoop/"
          script_file: "download.sh"
          c: "core-site.xml"
          h: "hdfs-site.xml"
          m: "mapred-site.xml"
  gather_facts: no
  tasks:
          - name: installing python
            yum:
                    name: python3
                    state: present

          - name: installing gdown
            pip:
                    name: gdown
                    executable: pip3.6

          - name: copying script for downloading hadoop and jdk
            copy:
                    src: "{{ script_file }}"
                    dest: "{{ path1 }}"

          - name: making file executable
            ansible.builtin.file:
                    path: "{{ path1 }}download.sh"
                    state: file
                    mode: "0775"

          - name: running script to download
            shell: "{{ path1 }}{{ script_file }}"
        
          - name: checking jdk
            shell: "sudo rpm -q jdk1.8"
            register: j
            ignore_errors: true

          - name: installing jdk
            shell: "sudo rpm -i /root/jdk-8u171-linux-x64.rpm"
            when: j.rc != 0

          - name: checking hadoop
            shell: "sudo rpm -q hadoop"
            register: h
            ignore_errors: true

          - name: installing hadoop
            shell: "sudo rpm -i /root/hadoop-1.2.1-1.x86_64.rpm --force"
            when: h.rc != 0

- name: namenode configuration
  hosts: hdfs_master
  gather_facts: no
  vars:
          path1: "/root/"
          path2: "/etc/hadoop/"
          script_file: "download.sh"
          c: "core-site.xml"
          h: "hdfs-site.xml"
          m: "mapred-site.xml"
  tasks:
          - name: copying hdfs-site.xml
            copy:
                  src: nhdfs-site.xml
                  dest: "{{ path2 }}hdfs-site.xml"

          - name: copying core-site.xml
            template:
                  src: core-site.xml
                  dest: "{{ path2 }}core-site.xml"

          - name: creating /nn directory
            file:
                  path: /nn
                  state: directory

          - name: checking namenode status
            command: "ls /nn/image"
            register: nn
            ignore_errors: true

          - name: formatting namenode
            shell: "sudo echo Y | hadoop namenode -format"
            when: nn.rc != 0
            ignore_errors: true

          - name: stopping namenode
            shell: "sudo hadoop-daemon.sh stop namenode"
            ignore_errors: true

          - name: starting namenode
            shell: "sudo hadoop-daemon.sh start namenode"
            ignore_errors: true

- name: datanode configuration
  hosts: hdfs_slave
  gather_facts: no
  vars:
          path1: "/root/"
          path2: "/etc/hadoop/"
          script_file: "download.sh"
          c: "core-site.xml"
          h: "hdfs-site.xml"
          m: "mapred-site.xml"
  tasks:
          - name: "copying {{ h }}"
            copy:
                  src: "d{{ h }}"
                  dest: "{{ path2 }}{{ h }}"

          - name: "copying {{ c }}"
            template:
                  src: "{{ c }}"
                  dest: "{{ path2 }}{{ c }}"

          - name: creating /dn directory
            file:
                  path: /dn
                  state: directory

          - name: starting datanode
            shell: "sudo hadoop-daemon.sh start datanode"
            ignore_errors: true

- name: job tracker configuration
  hosts: mr_master
  gather_facts: no
  vars:
          path1: "/root/"
          path2: "/etc/hadoop/"
          script_file: "download.sh"
          c: "core-site.xml"
          h: "hdfs-site.xml"
          m: "mapred-site.xml"
  tasks:
          - name: "copying {{ m }}"
            template:
                  src: "{{ m }}"
                  dest: "{{ path2 }}{{ m }}"

          - name: "copyging {{ c }}"
            template:
                  src: "{{ c }}"
                  dest: "{{ path2 }}{{ c }}"

          - name: starting job tracker
            shell: "sudo hadoop-daemon.sh start jobtracker"
            ignore_errors: true

- name: task tracker configuration
  hosts: mr_slave
  gather_facts: no
  vars:
          path1: "/root/"
          path2: "/etc/hadoop/"
          script_file: "download.sh"
          c: "core-site.xml"
          h: "hdfs-site.xml"
          m: "mapred-site.xml"
  tasks:
          - name: "copyging {{ m }}"
            template:
                  src: "{{ m }}"
                  dest: "{{ path2 }}{{ m }}"

          - name: starting task tracker
            shell: "sudo hadoop-daemon.sh start tasktracker"
            ignore_errors: true

- name: client configuration
  hosts: client
  gather_facts: no
  vars:
        path1: "/root/"
        path2: "/etc/hadoop/"
        script_file: "download.sh"
        c: "core-site.xml"
        h: "hdfs-site.xml"
        m: "mapred-site.xml"
  tasks:
          - name: "copyging {{ c }}"
            template:
                  src: "{{ c }}"
                  dest: "{{ path2 }}{{ c }}"

          - name: "copying {{ m }}"
            template:
                  src: "{{ m }}"
                  dest: "{{ path2 }}{{ m }}"
